Data analysis Wikipedia Data analysis From Wikipedia free encyclopedia Jump navigation Jump search Activity gaining insight from data Part series on Statistics Data visualization Major dimensions Exploratory data analysis Information design Interactive data visualization Descriptive statistics Inferential statistics Statistical graphics Plot Data analysis Infographic Data science Important figures Tamara Munzner Ben Shneiderman John W Tukey Edward Tufte Fernanda Vi gas Hadley Wickham Information graphic types Line chart Bar chart Histogram Scatterplot Boxplot Pareto chart Pie chart Area chart Control chart Run chart Stem leaf display Cartogram Small multiple Sparkline Table Related topics Data Information Big data Database Chartjunk Visual perception Regression analysis Statistical model Misleading graph v t e Computational physics Numerical analysis Simulation Data analysis Visualization Potentials Morse Long range potential Lennard Jones potential Yukawa potential Morse potential Fluid dynamics Finite difference Finite volume Finite element Boundary element Lattice Boltzmann Riemann solver Dissipative particle dynamics Smoothed particle hydrodynamics Turbulence models Monte Carlo methods Integration Gibbs sampling Metropolis algorithm Particle N body Particle in cell Molecular dynamics Scientists Godunov Ulam von Neumann Galerkin Lorenz Wilson v t e Data analysis process inspecting cleansing transforming modeling data with goal discovering useful information informing conclusion supporting decision making Data analysis has multiple facets approaches encompassing diverse techniques under variety names used in different business science social science domains In today s business world data analysis plays role in making decisions more scientific helping businesses operate more effectively Data mining particular data analysis technique that focuses on statistical modeling knowledge discovery predictive rather than purely descriptive purposes while business intelligence covers data analysis that relies heavily on aggregation focusing mainly on business information In statistical applications data analysis can be divided into descriptive statistics exploratory data analysis EDA confirmatory data analysis CDA EDA focuses on discovering new features in data while CDA focuses on confirming falsifying existing hypotheses Predictive analytics focuses on application statistical models predictive forecasting classification while text analytics applies statistical linguistic structural techniques extract classify information from textual sources species unstructured data All above are varieties data analysis Data integration precursor data analysis according whom data analysis closely linked data visualization data dissemination Contents process data analysis Data requirements Data collection Data processing Data cleaning Exploratory data analysis Modeling algorithms Data product Communication Quantitative messages Techniques analyzing quantitative data Analytical activities data users Barriers effective analysis Confusing fact opinion Cognitive biases Innumeracy Other topics Smart buildings Analytics business intelligence Education Practitioner notes Initial data analysis Quality data Quality measurements Initial transformations Did implementation study fulfill intentions research design Characteristics data sample Final stage initial data analysis Analysis Nonlinear analysis Main data analysis Exploratory confirmatory approaches Stability results Free software data analysis International data analysis contests See also References Citations Bibliography Further reading process data analysis edit Data science process flowchart from Doing Data Science by Schutt O Neil Analysis refers breaking whole into its separate components individual examination Data analysis process obtaining raw data converting it into information useful decision making by users Data are collected analyzed answer questions test hypotheses disprove theories Statistician John Tukey defined data analysis in as Procedures analyzing data techniques interpreting results such procedures ways planning gathering data make its analysis easier more precise more accurate all machinery results mathematical statistics which apply analyzing data are several phases that can be distinguished described below phases are iterative in that feedback from later phases may result in additional work in earlier phases CRISP framework used in data mining has similar steps Data requirements edit data are necessary as inputs analysis which specified based upon requirements those directing analysis customers will use finished product analysis general type entity upon which data will be collected referred as an experimental unit e g person population people Specific variables regarding population e g age income may be specified obtained Data may be numerical categorical i e text label numbers Data collection edit Data are collected from variety sources requirements may be communicated by analysts custodians data such as information technology personnel within an organization data may also be collected from sensors in environment such as traffic cameras satellites recording devices etc It may also be obtained through interviews downloads from online sources reading documentation Data processing edit phases intelligence cycle used convert raw information into actionable intelligence knowledge are conceptually similar phases in data analysis Data initially obtained must be processed organised analysis instance these may involve placing data into rows columns in table format i e structured data further analysis such as within spreadsheet statistical software Data cleaning edit Once processed organised data may be incomplete contain duplicates contain errors need data cleaning will arise from problems in way that data are entered stored Data cleaning process preventing correcting these errors Common tasks include record matching identifying inaccuracy data overall quality existing data deduplication column segmentation Such data problems can also be identified through variety analytical techniques example with financial information totals particular variables may be compared against separately published numbers believed be reliable Unusual amounts above below pre determined thresholds may also be reviewed are several types data cleaning that depend on type data such as phone numbers email addresses employers etc Quantitative data methods outlier detection can be used get rid likely incorrectly entered data Textual data spell checkers can be used lessen amount mistyped words but it harder tell if words themselves are correct Exploratory data analysis edit Once data are cleaned it can be analyzed Analysts may apply variety techniques referred as exploratory data analysis begin understanding messages contained in data process exploration may result in additional data cleaning additional requests data so these activities may be iterative in nature Descriptive statistics such as average median may be generated help understand data Data visualization may also be used examine data in graphical format obtain additional insight regarding messages within data Modeling algorithms edit Mathematical formulas models called algorithms may be applied data identify relationships among variables such as correlation causation In general terms models may be developed evaluate particular variable in data based on other variable s in data with some residual error depending on model accuracy i e Data Model Error Inferential statistics includes techniques measure relationships between particular variables example regression analysis may be used model whether change in advertising independent variable X explains variation in sales dependent variable Y In mathematical terms Y sales function X advertising It may be described as Y aX b error model designed such that b minimize error model predicts Y given range values X Analysts may attempt build models that are descriptive data simplify analysis communicate results Data product edit data product computer application that takes data inputs generates outputs feeding them back into environment It may be based on model algorithm An example an application that analyzes data about customer purchasing history recommends other purchases customer might enjoy Communication edit Data visualization understand results data analysis Main article Data visualization Once data are analyzed it may be reported in many formats users analysis support requirements users may have feedback which results in additional analysis As such much analytical cycle iterative determining communicate results analyst may consider data visualization techniques help clearly efficiently communicate message audience Data visualization uses information displays such as tables charts help communicate key messages contained in data Tables are helpful user might look up specific numbers while charts e g bar charts line charts may help explain quantitative messages contained in data Quantitative messages edit Main article Data visualization time series illustrated with line chart demonstrating trends in U S federal spending revenue over time scatterplot illustrating correlation between two variables inflation unemployment measured at points in time Stephen Few described eight types quantitative messages that users may attempt understand communicate from set data associated graphs used help communicate message Customers specifying requirements analysts performing data analysis may consider these messages during course process Time series single variable captured over period time such as unemployment rate over year period line chart may be used demonstrate trend Ranking Categorical subdivisions are ranked in ascending descending order such as ranking sales performance measure by sales persons category with each sales person categorical subdivision during single period bar chart may be used show comparison across sales persons Part whole Categorical subdivisions are measured as ratio whole i e percentage out pie chart bar chart can show comparison ratios such as market share represented by competitors in market Deviation Categorical subdivisions are compared against reference such as comparison actual vs budget expenses several departments business given time period bar chart can show comparison actual versus reference amount Frequency distribution Shows number observations particular variable given interval such as number years in which stock market return between intervals such as etc histogram type bar chart may be used this analysis Correlation Comparison between observations represented by two variables X Y determine if they tend move in same opposite directions example plotting unemployment X inflation Y sample months scatter plot typically used this message Nominal comparison Comparing categorical subdivisions in no particular order such as sales volume by product code bar chart may be used this comparison Geographic geospatial Comparison variable across map layout such as unemployment rate by state number persons on various floors building cartogram typical graphic used Techniques analyzing quantitative data edit See also Problem solving Author Jonathan Koomey has recommended series best practices understanding quantitative data These include Check raw data anomalies prior performing analysis Re perform important calculations such as verifying columns data that are formula driven Confirm main totals are sum subtotals Check relationships between numbers that should be related in predictable way such as ratios over time Normalize numbers make comparisons easier such as analyzing amounts per person relative GDP as an index value relative base year Break problems into component parts by analyzing factors that led results such as DuPont analysis return on equity variables under examination analysts typically obtain descriptive statistics them such as mean average median standard deviation They may also analyze distribution key variables see individual values cluster around mean An illustration MECE principle used data analysis consultants at McKinsey Company named technique breaking quantitative problem down into its component parts called MECE principle Each layer can be broken down into its components each sub components must be mutually exclusive each other collectively add up layer above them relationship referred as Mutually Exclusive Collectively Exhaustive MECE example profit by definition can be broken down into total revenue total cost In turn total revenue can be analyzed by its components such as revenue divisions B C which are mutually exclusive each other should add total revenue collectively exhaustive Analysts may use robust statistical measurements solve certain analytical problems Hypothesis testing used particular hypothesis about true state affairs made by analyst data gathered determine whether that state affairs true false example hypothesis might be that Unemployment has no effect on inflation which relates an economics concept called Phillips Curve Hypothesis testing involves considering likelihood Type type II errors which relate whether data supports accepting rejecting hypothesis Regression analysis may be used analyst trying determine extent which independent variable X affects dependent variable Y e g extent do changes in unemployment rate X affect inflation rate Y This an attempt model fit an equation line curve data such that Y function X Necessary condition analysis NCA may be used analyst trying determine extent which independent variable X allows variable Y e g extent certain unemployment rate X necessary certain inflation rate Y Whereas multiple regression analysis uses additive logic each X variable can produce outcome X s can compensate each other they are sufficient but not necessary necessary condition analysis NCA uses necessity logic one more X variables allow outcome exist but may not produce it they are necessary but not sufficient Each single necessary condition must be present compensation not possible Analytical activities data users edit Users may have particular data points interest within data set as opposed general messaging outlined above Such low level user analytic activities are presented in following table taxonomy can also be organized by three poles activities retrieving values finding data points arranging data points Task General Description Pro Forma Abstract Examples Retrieve Value Given set specific cases find attributes those cases are values attributes X Y Z in data cases B C mileage per gallon Ford Mondeo long movie Gone with Wind Filter Given some concrete conditions on attribute values find data cases satisfying those conditions Which data cases satisfy conditions B C Kellogg s cereals have high fiber comedies have won awards Which funds underperformed SP Compute Derived Value Given set data cases compute an aggregate numeric representation those data cases value aggregation function F over given set S data cases average calorie content Post cereals gross income all stores combined many manufacturers cars are Find Extremum Find data cases possessing an extreme value an attribute over its range within data set are top bottom N data cases with respect attribute car with highest MPG director film has won most awards Marvel Studios film has most recent release date Sort Given set data cases rank them according some ordinal metric sorted order set S data cases according value attribute Order cars by weight Rank cereals by calories Determine Range Given set data cases an attribute interest find span values within set range values attribute in set S data cases range film lengths range car horsepowers actresses are in data set Characterize Distribution Given set data cases quantitative attribute interest characterize distribution that attribute s values over set distribution values attribute in set S data cases distribution carbohydrates in cereals age distribution shoppers Find Anomalies Identify any anomalies within given set data cases with respect given relationship expectation e g statistical outliers Which data cases in set S data cases have unexpected exceptional values Are exceptions relationship between horsepower acceleration Are any outliers in protein Cluster Given set data cases find clusters similar attribute values Which data cases in set S data cases are similar in value attributes X Y Z Are groups cereals w similar fat calories sugar cluster typical film lengths Correlate Given set data cases two attributes determine useful relationships between values those attributes correlation between attributes X Y over given set S data cases correlation between carbohydrates fat correlation between country origin MPG Do different genders have preferred payment method trend increasing film length over years Contextualization Given set data cases find contextual relevancy data users Which data cases in set S data cases are relevant current users context Are groups restaurants that have foods based on my current caloric intake Barriers effective analysis edit Barriers effective analysis may exist among analysts performing data analysis among audience Distinguishing fact from opinion cognitive biases innumeracy are all challenges sound data analysis Confusing fact opinion edit are entitled own opinion but are not entitled own facts Daniel Patrick Moynihan Effective analysis requires obtaining relevant facts answer questions support conclusion formal opinion test hypotheses Facts by definition are irrefutable meaning that any person involved in analysis should be able agree upon them example in August Congressional Budget Office CBO estimated that extending Bush tax cuts time period would add approximately trillion national debt Everyone should be able agree that indeed this CBO reported they can all examine report This makes it fact Whether persons agree disagree with CBO own opinion As another example auditor public company must arrive at formal opinion on whether financial statements publicly traded corporations are fairly stated in all material respects This requires extensive analysis factual data evidence support opinion making leap from facts opinions always possibility that opinion erroneous Cognitive biases edit are variety cognitive biases that can adversely affect analysis example confirmation bias tendency search interpret information in way that confirms one s preconceptions In addition individuals may discredit information that does not support views Analysts may be trained specifically be aware these biases overcome them In his book Psychology Intelligence Analysis retired CIA analyst Richards Heuer wrote that analysts should clearly delineate assumptions chains inference specify degree source uncertainty involved in conclusions He emphasized procedures help surface debate alternative points view Innumeracy edit Effective analysts are generally adept with variety numerical techniques However audiences may not have such literacy with numbers numeracy they are said be innumerate Persons communicating data may also be attempting mislead misinform deliberately using bad numerical techniques example whether number rising falling may not be key factor More important may be number relative another number such as size government revenue spending relative size economy GDP amount cost relative revenue in corporate financial statements This numerical technique referred as normalization common sizing are many such techniques employed by analysts whether adjusting inflation i e comparing real vs nominal data considering population increases demographics etc Analysts apply variety techniques address various quantitative messages described in section above Analysts may also analyze data under different assumptions scenarios example analysts perform financial statement analysis they will often recast financial statements under different assumptions help arrive at an estimate future cash flow which they then discount present value based on some interest rate determine valuation company its stock Similarly CBO analyzes effects various policy options on government s revenue outlays deficits creating alternative future scenarios key measures Other topics edit Smart buildings edit data analytics approach can be used in order predict energy consumption in buildings different steps data analysis process are carried out in order realise smart buildings building management control operations including heating ventilation air conditioning lighting security are realised automatically by miming needs building users optimising resources like energy time Analytics business intelligence edit Main article Analytics Analytics extensive use data statistical quantitative analysis explanatory predictive models fact based management drive decisions actions It subset business intelligence which set technologies processes that use data understand analyze business performance Education edit Analytic activities data visualization users In education most educators have access data system purpose analyzing student data These data systems present data educators in an over counter data format embedding labels supplemental documentation help system making key package display content decisions improve accuracy educators data analyses Practitioner notes edit This section contains rather technical explanations that may assist practitioners but are beyond typical scope Wikipedia article Initial data analysis edit most important distinction between initial data analysis phase main analysis phase that during initial data analysis one refrains from any analysis that aimed at answering original research question initial data analysis phase guided by following four questions Quality data edit quality data should be checked as early as possible Data quality can be assessed in several ways using different types analysis frequency counts descriptive statistics mean standard deviation median normality skewness kurtosis frequency histograms n variables are compared with coding schemes variables external data set possibly corrected if coding schemes are not comparable Test common method variance choice analyses assess data quality during initial data analysis phase depends on analyses that will be conducted in main analysis phase Quality measurements edit quality measurement instruments should only be checked during initial data analysis phase this not focus research question study One should check whether structure measurement instruments corresponds structure reported in literature are two ways assess measurement NOTE only one way seems be listed Analysis homogeneity internal consistency which gives an indication reliability measurement instrument During this analysis one inspects variances items scales Cronbach s scales change in Cronbach s alpha an item would be deleted from scale Initial transformations edit After assessing quality data measurements one might decide impute missing data perform initial transformations one more variables although this can also be done during main analysis phase Possible transformations variables are Square root transformation if distribution differs moderately from normal Log transformation if distribution differs substantially from normal Inverse transformation if distribution differs severely from normal Make categorical ordinal dichotomous if distribution differs severely from normal no transformations help Did implementation study fulfill intentions research design edit One should check success randomization procedure instance by checking whether background substantive variables are equally distributed within across groups If study did not need use randomization procedure one should check success non random sampling instance by checking whether all subgroups population interest are represented in sample Other possible data distortions that should be checked are dropout this should be identified during initial data analysis phase Item nonresponse whether this random not should be assessed during initial data analysis phase Treatment quality using manipulation checks Characteristics data sample edit In any report article structure sample must be accurately described It especially important exactly determine structure sample specifically size subgroups subgroup analyses will be performed during main analysis phase characteristics data sample can be assessed by looking at Basic statistics important variables Scatter plots Correlations associations Cross tabulations Final stage initial data analysis edit During final stage findings initial data analysis are documented necessary preferable possible corrective actions are taken Also original plan main data analyses can should be specified in more detail rewritten In order do this several decisions about main data analyses can should be made In case non normals should one transform variables make variables categorical ordinal dichotomous adapt analysis method In case missing data should one neglect impute missing data which imputation technique should be used In case outliers should one use robust analysis techniques In case items do not fit scale should one adapt measurement instrument by omitting items rather ensure comparability with other uses measurement instrument s In case small subgroups should one drop hypothesis about inter group differences use small sample techniques like exact tests bootstrapping In case randomization procedure seems be defective can should one calculate propensity scores include them as covariates in main analyses Analysis edit Several analyses can be used during initial data analysis phase Univariate statistics single variable Bivariate associations correlations Graphical techniques scatter plots It important take measurement levels variables into account analyses as special statistical techniques are available each level Nominal ordinal variables Frequency counts numbers percentages Associations circumambulations crosstabulations hierarchical loglinear analysis restricted maximum variables loglinear analysis identify relevant important variables possible confounders Exact tests bootstrapping in case subgroups are small Computation new variables Continuous variables Distribution Statistics M SD variance skewness kurtosis Stem leaf displays Box plots Nonlinear analysis edit Nonlinear analysis often necessary data recorded from nonlinear system Nonlinear systems can exhibit complex dynamic effects including bifurcations chaos harmonics subharmonics that cannot be analyzed using simple linear methods Nonlinear data analysis closely related nonlinear system identification Main data analysis edit In main analysis phase analyses aimed at answering research question are performed as well as any other relevant analysis needed write first draft research report Exploratory confirmatory approaches edit In main analysis phase either an exploratory confirmatory approach can be adopted Usually approach decided before data collected In an exploratory analysis no clear hypothesis stated before analysing data data searched models that describe data well In confirmatory analysis clear hypotheses about data are tested Exploratory data analysis should be interpreted carefully testing multiple models at once high chance on finding at least one them be significant but this can be due type error It important always adjust significance level testing multiple models with example Bonferroni correction Also one should not follow up an exploratory analysis with confirmatory analysis in same dataset An exploratory analysis used find ideas theory but not test that theory as well model found exploratory in dataset then following up that analysis with confirmatory analysis in same dataset could simply mean that results confirmatory analysis are due same type error that resulted in exploratory model in first place confirmatory analysis therefore will not be more informative than original exploratory analysis Stability results edit It important obtain some indication about generalizable results are While this often difficult check one can look at stability results Are results reliable reproducible are two main ways doing that Cross validation By splitting data into multiple parts we can check if an analysis like fitted model based on one part data generalizes another part data as well Cross validation generally inappropriate though if are correlations within data e g with panel data Hence other methods validation sometimes need be used more on this topic see statistical model validation Sensitivity analysis procedure study behavior system model global parameters are systematically varied One way do that via bootstrapping Free software data analysis edit Notable free software data analysis include DevInfo database system endorsed by United Nations Development Group monitoring analyzing human development ELKI data mining framework in Java with data mining oriented visualization functions KNIME Konstanz Information Miner user friendly comprehensive data analytics framework Orange visual programming tool featuring interactive data visualization methods statistical data analysis data mining machine learning Pandas Python library data analysis PAW FORTRAN C data analysis framework developed at CERN R programming language software environment statistical computing graphics ROOT C data analysis framework developed at CERN SciPy Python library data analysis Data Analysis NET library data analysis transformation International data analysis contests edit Different companies organizations hold data analysis contests encourage researchers utilize data solve particular question using data analysis few examples well known international data analysis contests are as follows Kaggle competition held by Kaggle LTPP data analysis contest held by FHWA ASCE See also edit Actuarial science Analytics Big data Business intelligence Censoring statistics Computational physics Data acquisition Data blending Data governance Data mining Data Presentation Architecture Data science Digital signal processing Dimension reduction Early case assessment Exploratory data analysis Fourier analysis Machine learning Multilinear PCA Multilinear subspace learning Multiway data analysis Nearest neighbor search Nonlinear system identification Predictive analytics Principal component analysis Qualitative research Scientific computing Structured data analysis statistics System identification Test method Text analytics Unstructured data Wavelet References edit Citations edit Xia B S Gong P Review business intelligence through data analysis Benchmarking doi BIJ Exploring Data Analysis b c Judd Charles McCleland Gary Data Analysis Harcourt Brace Jovanovich ISBN John Tukey Future Data Analysis July b c d e f g Schutt Rachel O Neil Cathy Doing Data Science O Reilly Media ISBN Clean Data in CRM Key Generate Sales Ready Leads Boost Revenue Pool Retrieved th July Data Cleaning Microsoft Research Retrieved October b c Perceptual Edge Jonathan Koomey Best practices understanding quantitative data February Hellerstein Joseph February Quantitative Data Cleaning Large Databases PDF EECS Computer Science Division Retrieved October Stephen Few Perceptual Edge Selecting Right Graph Message September Behrens Principles Procedures Exploratory Data Analysis American Psychological Association Grandjean Martin La connaissance est un r seau PDF Les Cahiers du Num rique doi lcn Stephen Few Perceptual Edge Selecting Right Graph Message Stephen Few Perceptual Edge Graph Selection Matrix Robert Amar James Eagan John Stasko Low Level Components Analytic Activity in Information Visualization William Newman Preliminary Analysis Products HCI Research Using Pro Forma Abstracts Mary Shaw Makes Good Research in Software Engineering b ConTaaS An Approach Internet Scale Contextualisation Developing Efficient Internet Things Applications ScholarSpace HICSS Retrieved May Congressional Budget Office Budget Economic Outlook August Table on Page PDF Retrieved Introduction cia gov Bloomberg Barry Ritholz Bad Math that Passes Insight October Gonz lez Vidal Aurora Moreno Cano Victoria Towards energy efficiency smart buildings models based on intelligent data analytics Procedia Computer Science Elsevier doi j procs Davenport Thomas Harris Jeanne Competing on Analytics O Reilly ISBN Aarons D Report finds states on course build pupil data systems Education Week Rankin J March data Systems reports can either fight propagate data analysis error epidemic educator leaders can help Presentation conducted from Technology Information Center Administrative Leadership TICAL School Leadership Summit Ad r p Ad r pp Ad r pp Ad r p Tabachnick Fidell p Ad r pp Ad r p Ad r pp Ad r pp Ad r pp Billings S Nonlinear System Identification NARMAX Methods in Time Frequency Spatio Temporal Domains Wiley Ad r b p Ad r b pp Ad r b pp machine learning community takes on Higgs Symmetry Magazine July Retrieved January Nehme Jean September LTPP International Data Analysis Contest Federal Highway Administration Retrieved October Data Gov Long Term Pavement Performance LTPP May Retrieved November Bibliography edit Ad r Herman J Chapter Phases initial steps in data analysis In Ad r Herman J Mellenbergh Gideon J Hand David J eds Advising on research methods consultant s companion Huizen Netherlands Johannes van Kessel Pub pp ISBN OCLC Ad r Herman J b Chapter main analysis phase In Ad r Herman J Mellenbergh Gideon J Hand David J eds Advising on research methods consultant s companion Huizen Netherlands Johannes van Kessel Pub pp ISBN OCLC Tabachnick B G Fidell L S Chapter Cleaning up act Screening data prior analysis In B G Tabachnick L S Fidell Eds Using Multivariate Statistics Fifth Edition pp Boston Pearson Education Inc Allyn Bacon Further reading edit Wikiversity has learning resources about Data analysis Ad r H J Mellenbergh G J with contributions by D J Hand Advising on Research Methods Consultant s Companion Huizen Netherlands Johannes van Kessel Publishing Chambers John M Cleveland William S Kleiner Beat Tukey Paul Graphical Methods Data Analysis Wadsworth Duxbury Press ISBN X Fandango Armando Python Data Analysis nd Edition Packt Publishers Juran Joseph M Godfrey Blanton Juran s Quality Handbook th Edition New York McGraw Hill ISBN X Lewis Beck Michael S Data Analysis an Introduction Sage Publications Inc ISBN NIST SEMATECH Handbook Statistical Methods Pyzdek T Quality Engineering Handbook ISBN Richard Veryard Pragmatic Data Analysis Oxford Blackwell Scientific Publications ISBN Tabachnick B G Fidell L S Using Multivariate Statistics th Edition Boston Pearson Education Inc Allyn Bacon ISBN Authority control GND v t e Data Analysis Archaeology Cleansing Collection Compression Corruption Curation Degradation Editing ETL Farming Format management Fusion Integration Integrity Library Loss Management Migration Mining Pre processing Preservation Protection privacy Recovery Reduction Retention Quality Science Scraping Scrubbing Security Stewardship Storage Validation Warehouse Wrangling munging Retrieved from https en wikipedia org w index php title Data analysis oldid Categories Data analysis Scientific method Computational fields study Hidden categories Articles with short description All articles with specifically marked weasel worded phrases Articles with specifically marked weasel worded phrases from March Wikipedia articles needing clarification from March Wikipedia articles with GND identifiers Navigation menu Personal tools Not logged in Talk Contributions Create account Log in Namespaces Article Talk Variants Views Read Edit View history More Search Navigation Main page Contents Featured content Current events Random article Donate Wikipedia Wikipedia store Interaction Help About Wikipedia Community portal Recent changes Contact page Tools links here Related changes Upload file Special pages Permanent link Page information Wikidata item Cite this page In other projects Wikimedia Commons Print export Create book Download as PDF Printable version Languages e tina Cymraeg Deutsch Eesti Espa ol Esperanto Fran ais Italiano Magyar Bahasa Melayu Polski Portugu s Rom n srpski Suomi T rk e Edit links This page was last edited on November at UTC Text available under Creative Commons Attribution ShareAlike License additional terms may apply By using this site agree Terms Use Privacy Policy Wikipedia registered trademark Wikimedia Foundation Inc non profit organization Privacy policy About Wikipedia Disclaimers Contact Wikipedia Developers Statistics Cookie statement Mobile view