Compiler Wikipedia Compiler From Wikipedia free encyclopedia Jump navigation Jump search This article about software translate computer languages manga see Compiler manga Compile compiling redirect here software company see Compile company other uses see compilation Program execution General concepts Code Translation Compiler Compile time Optimizing compiler Intermediate representation IR Execution Runtime system Runtime Executable Interpreter Virtual machine Types code Source code Object code Bytecode Machine code Microcode Compilation strategies Just in time JIT Tracing just in time Ahead time AOT Transcompilation Recompilation Notable runtimes Android Runtime ART Common Language Runtime CLR Mono crt HHVM Java virtual machine JVM Objective C V Node js PyPy Zend Engine Notable compilers toolchains GNU Compiler Collection GCC LLVM Clang v t e compiler computer program that translates computer code written in one programming language source language into another language target language name compiler primarily used programs that translate source code from high level programming language lower level language e g assembly language object code machine code create an executable program p However are many different types compilers If compiled program can run on computer whose CPU operating system different from one on which compiler runs compiler cross compiler bootstrap compiler written in language that it intends compile program that translates from low level language higher level one decompiler program that translates between high level languages usually called source source compiler transpiler language rewriter usually program that translates form expressions without change language term compiler compiler refers tools used create parsers that perform syntax analysis compiler likely perform many all following operations preprocessing lexical analysis parsing semantic analysis syntax directed translation conversion input programs an intermediate representation code optimization code generation Compilers implement these operations in phases that promote efficient design correct transformations source input target output Program faults caused by incorrect compiler behavior can be very difficult track down work around therefore compiler implementers invest significant effort ensure compiler correctness Compilers are not only language processor used transform source programs An interpreter computer software that transforms then executes indicated operations p translation process influences design computer languages which leads preference compilation interpretation In practice an interpreter can be implemented compiled languages compilers can be implemented interpreted languages Contents History Compiler construction One pass versus multi pass compilers Three stage compiler structure Front end Middle end Back end Compiler correctness Compiled versus interpreted languages Types See also Notes References External links History edit Main article History compiler construction diagram operation typical multi language multi target compiler Theoretical computing concepts developed by scientists mathematicians engineers formed basis digital modern computing development during World War II Primitive binary languages evolved digital devices only understand ones zeros circuit patterns in underlying machine architecture In late s assembly languages were created offer more workable abstraction computer architectures Limited memory capacity early computers led substantial technical challenges first compilers were designed Therefore compilation process needed be divided into several small programs front end programs produce analysis products used by back end programs generate target code As computer technology provided more resources compiler designs could align better with compilation process It usually more productive programmer use high level language so development high level languages followed naturally from capabilities offered by digital computers High level languages are formal languages that are strictly defined by syntax semantics which form high level language architecture Elements these formal languages include Alphabet any finite set symbols String finite sequence symbols Language any set strings on an alphabet sentences in language may be defined by set rules called grammar Backus Naur form BNF describes syntax sentences language was used syntax Algol by John Backus ideas derive from context free grammar concepts by Noam Chomsky linguist BNF its extensions have become standard tools describing syntax programming notations in many cases parts compilers are generated automatically from BNF description In s Konrad Zuse designed an algorithmic programming language called Plankalk l Plan Calculus While no actual implementation occurred until s it presented concepts later seen in APL designed by Ken Iverson in late s APL language mathematical computations High level language design during formative years digital computing provided useful programming tools variety applications FORTRAN Formula Translation engineering science applications considered be first high level language COBOL Common Business Oriented Language evolved from FLOW MATIC become dominant high level language business applications LISP List Processor symbolic computation Compiler technology evolved from need strictly defined transformation high level source program into low level target program digital computer compiler could be viewed as front end deal with analysis source code back end synthesize analysis into target code Optimization between front end back end could produce more efficient target code Some early milestones in development compiler technology An Autocode compiler developed by Alick Glennie Manchester Mark computer at University Manchester considered by some be first compiled programming language Grace Hopper s team at Remington Rand wrote compiler programming language coined term compiler describe it although compiler functioned more as loader linker than modern notion full compiler team led by John Backus at IBM developed FORTRAN which usually considered first high level language In they completed FORTRAN compiler that generally credited as having introduced first unambiguously complete compiler Conference on Data Systems Language CODASYL initiated development COBOL COBOL design drew on FLOW MATIC By early s COBOL was compiled on multiple architectures John McCarthy at MIT designed LISP symbol processing capabilities provided useful features artificial intelligence research In LISP release noted some tools an interpreter written by Stephen Russell Daniel J Edwards compiler assembler written by Tim Hart Mike Levin Early operating systems software were written in assembly language In s early s use high level languages system programming was still controversial due resource limitations However several research industry efforts began shift toward high level systems programming languages example BCPL BLISS B C BCPL Basic Combined Programming Language designed in by Martin Richards at University Cambridge was originally developed as compiler writing tool Several compilers have been implemented Richards book provides insights language its compiler BCPL was not only an influential systems programming language that still used in research but also provided basis design B C languages BLISS Basic Language Implementation System Software was developed Digital Equipment Corporation DEC PDP computer by W Wulf s Carnegie Mellon University CMU research team CMU team went on develop BLISS compiler one year later in Multics Multiplexed Information Computing Service time sharing operating system project involved MIT Bell Labs General Electric later Honeywell was led by Fernando Corbat from MIT Multics was written in PL language developed by IBM IBM User Group IBM s goal was satisfy business scientific systems programming requirements were other languages that could have been considered but PL offered most complete solution even though it had not been implemented first few years Mulitics project subset language could be compiled assembly language with Early PL EPL compiler by Doug McIlory Bob Morris from Bell Labs EPL supported project until boot strapping compiler full PL could be developed Bell Labs left Multics project in Over time hope was replaced by frustration as group effort initially failed produce an economically useful system Continued participation would drive up project support costs So researchers turned other development efforts system programming language B based on BCPL concepts was written by Dennis Ritchie Ken Thompson Ritchie created boot strapping compiler B wrote Unics Uniplexed Information Computing Service operating system PDP in B Unics eventually became spelled Unix Bell Labs started development expansion C based on B BCPL BCPL compiler had been transported Multics by Bell Labs BCPL was preferred language at Bell Labs Initially front end program Bell Labs B compiler was used while C compiler was developed In new PDP provided resource define extensions B rewrite compiler By design C language was essentially complete Unix kernel PDP was rewritten in C Steve Johnson started development Portable C Compiler PCC support retargeting C compilers new machines Object oriented programming OOP offered some interesting possibilities application development maintenance OOP concepts go further back but were part LISP Simula language science At Bell Labs development C became interested in OOP C was first used in systems programming initial design leveraged C language systems programming capabilities with Simula concepts Object oriented facilities were added in Cfront program implemented C front end C language compiler In subsequent years several C compilers were developed as C popularity grew In many application domains idea using higher level language quickly caught on expanding functionality supported by newer programming languages increasing complexity computer architectures compilers became more complex DARPA Defense Advanced Research Projects Agency sponsored compiler project with Wulf s CMU research team in Production Quality Compiler Compiler PQCC design would produce Production Quality Compiler PQC from formal definitions source language target PQCC tried extend term compiler compiler beyond traditional meaning as parser generator e g Yacc without much success PQCC might more properly be referred as compiler generator PQCC research into code generation process sought build truly automatic compiler writing system effort discovered designed phase structure PQC BLISS compiler provided initial structure phases included analyses front end intermediate translation virtual machine middle end translation target back end TCOL was developed PQCC research handle language specific constructs in intermediate representation Variations TCOL supported various languages PQCC project investigated techniques automated compiler construction design concepts proved useful in optimizing compilers compilers object oriented programming language Ada Ada Stoneman Document formalized program support environment APSE along with kernel KAPSE minimal MAPSE An Ada interpreter NYU ED supported development standardization efforts with American National Standards Institute ANSI International Standards Organization ISO Initial Ada compiler development by U S Military Services included compilers in complete integrated design environment along lines Stoneman Document Army Navy worked on Ada Language System ALS project targeted DEC VAX architecture while Air Force started on Ada Integrated Environment AIE targeted IBM series While projects did not provide desired results they did contribute overal effort on Ada development Other Ada compiler efforts got underway in Britain at University York in Germany at University Karlsruhe In U S Verdix later acquired by Rational delivered Verdix Ada Development System VADS Army VADS provided set development tools including compiler Unix VADS could be hosted on variety Unix platforms such as DEC Ultrix Sun Solaris targeted Motorola in an Army CECOM evaluation were soon many Ada compilers available that passed Ada Validation tests Free Software Foundation GNU project developed GNU Compiler Collection GCC which provides core capability support multiple languages targets Ada version GNAT one most widely used Ada compilers GNAT free but also commercial support example AdaCore was founded in provide commercial software solutions Ada GNAT Pro includes GNU GCC based GNAT with tool suite provide an integrated development environment High level languages continued drive compiler research development Focus areas included optimization automatic code generation Trends in programming languages development environments influenced compiler technology More compilers became included in language distributions PERL Java Development Kit as component an IDE VADS Eclipse Ada Pro interrelationship interdependence technologies grew advent web services promoted growth web languages scripting languages Scripts trace back early days Command Line Interfaces CLI user could enter commands be executed by system User Shell concepts developed with languages write shell programs Early Windows designs offered simple batch programming capability conventional transformation these language used an interpreter While not widely used Bash Batch compilers have been written More recently sophisticated interpreted languages became part developers tool kit Modern scripting languages include PHP Python Ruby Lua Lua widely used in game development All these have interpreter compiler support field compiling began in late s its focus was limited translation high level language programs into machine code compiler field increasingly intertwined with other disciplines including computer architecture programming languages formal methods software engineering computer security Compiler Research Next Years article noted importance object oriented languages Java Security parallel computing were cited among future research targets Compiler construction edit This section does not cite any sources Please help improve this section by adding citations reliable sources Unsourced material may be challenged removed Find sources Compiler news newspapers books scholar JSTOR September Learn remove this template message compiler implements formal transformation from high level source program low level target program Compiler design can define an end end solution tackle defined subset that interfaces with other compilation tools e g preprocessors assemblers linkers Design requirements include rigorously defined interfaces both internally between compiler components externally between supporting toolsets In early days approach taken compiler design was directly affected by complexity computer language be processed experience person s designing it resources available Resource limitations led need pass through source code more than once compiler relatively simple language written by one person might be single monolithic piece software However as source language grows in complexity design may be split into number interdependent phases Separate phases provide design improvements that focus development on functions in compilation process One pass versus multi pass compilers edit Classifying compilers by number passes has its background in hardware resource limitations computers Compiling involves performing lots work early computers did not have enough memory contain one program that did all this work So compilers were split up into smaller programs which each made pass over source some representation it performing some required analysis translations ability compile in single pass has classically been seen as benefit it simplifies job writing compiler one pass compilers generally perform compilations faster than multi pass compilers Thus partly driven by resource limitations early systems many early languages were specifically designed so that they could be compiled in single pass e g Pascal In some cases design language feature may require compiler perform more than one pass over source instance consider declaration appearing on line source which affects translation statement appearing on line In this case first pass needs gather information about declarations appearing after statements that they affect with actual translation happening during subsequent pass disadvantage compiling in single pass that it not possible perform many sophisticated optimizations needed generate high quality code It can be difficult count exactly many passes an optimizing compiler makes instance different phases optimization may analyse one expression many times but only analyse another expression once Splitting compiler up into small programs technique used by researchers interested in producing provably correct compilers Proving correctness set small programs often requires less effort than proving correctness larger single equivalent program Three stage compiler structure edit Compiler design Regardless exact number phases in compiler design phases can be assigned one three stages stages include front end middle end back end front end verifies syntax semantics according specific source language statically typed languages it performs type checking by collecting type information If input program syntactically incorrect has type error it generates error warning messages usually identifying location in source code problem was detected in some cases actual error may be much earlier in program Aspects front end include lexical analysis syntax analysis semantic analysis front end transforms input program into an intermediate representation IR further processing by middle end This IR usually lower level representation program with respect source code middle end performs optimizations on IR that are independent CPU architecture being targeted This source code machine code independence intended enable generic optimizations be shared between versions compiler supporting different languages target processors Examples middle end optimizations are removal useless dead code elimination unreachable code reachability analysis discovery propagation constant values constant propagation relocation computation less frequently executed place e g out loop specialization computation based on context Eventually producing optimized IR that used by back end back end takes optimized IR from middle end It may perform more analysis transformations optimizations that are specific target CPU architecture back end generates target dependent assembly code performing register allocation in process back end performs instruction scheduling which re orders instructions keep parallel execution units busy by filling delay slots Although most optimization problems are NP hard heuristic techniques solving them are well developed currently implemented in production quality compilers Typically output back end machine code specialized particular processor operating system This front middle back end approach makes it possible combine front ends different languages with back ends different CPUs while sharing optimizations middle end Practical examples this approach are GNU Compiler Collection LLVM Amsterdam Compiler Kit which have multiple front ends shared optimizations multiple back ends Front end edit Lexer parser example C Starting from sequence characters if net total net tax scanner composes sequence tokens categorizes each them example as identifier reserved word number literal operator latter sequence transformed by parser into syntax tree which then treated by remaining compiler phases scanner parser handles regular properly context free parts grammar C respectively front end analyzes source code build an internal representation program called intermediate representation IR It also manages symbol table data structure mapping each symbol in source code associated information such as location type scope While frontend can be single monolithic function program as in scannerless parser it more commonly implemented analyzed as several phases which may execute sequentially concurrently This method favored due its modularity separation concerns Most commonly today frontend broken into three phases lexical analysis also known as lexing syntax analysis also known as scanning parsing semantic analysis Lexing parsing comprise syntactic analysis word syntax phrase syntax respectively in simple cases these modules lexer parser can be automatically generated from grammar language though in more complex cases these require manual modification lexical grammar phrase grammar are usually context free grammars which simplifies analysis significantly with context sensitivity handled at semantic analysis phase semantic analysis phase generally more complex written by hand but can be partially fully automated using attribute grammars These phases themselves can be further broken down lexing as scanning evaluating parsing as building concrete syntax tree CST parse tree then transforming it into an abstract syntax tree AST syntax tree In some cases additional phases are used notably line reconstruction preprocessing but these are rare main phases front end include following Line reconstruction converts input character sequence canonical form ready parser Languages which strop keywords allow arbitrary spaces within identifiers require this phase top down recursive descent table driven parsers used in s typically read source one character at time did not require separate tokenizing phase Atlas Autocode Imp some implementations ALGOL Coral are examples stropped languages whose compilers would have Line Reconstruction phase Preprocessing supports macro substitution conditional compilation Typically preprocessing phase occurs before syntactic semantic analysis e g in case C preprocessor manipulates lexical tokens rather than syntactic forms However some languages such as Scheme support macro substitutions based on syntactic forms Lexical analysis also known as lexing tokenization breaks source code text into sequence small pieces called lexical tokens This phase can be divided into two stages scanning which segments input text into syntactic units called lexemes assign them category evaluating which converts lexemes into processed value token pair consisting token name an optional token value Common token categories may include identifiers keywords separators operators literals comments although set token categories varies in different programming languages lexeme syntax typically regular language so finite state automaton constructed from regular expression can be used recognize it software doing lexical analysis called lexical analyzer This may not be separate step it can be combined with parsing step in scannerless parsing in which case parsing done at character level not token level Syntax analysis also known as parsing involves parsing token sequence identify syntactic structure program This phase typically builds parse tree which replaces linear sequence tokens with tree structure built according rules formal grammar which define language s syntax parse tree often analyzed augmented transformed by later phases in compiler Semantic analysis adds semantic information parse tree builds symbol table This phase performs semantic checks such as type checking checking type errors object binding associating variable function references with definitions definite assignment requiring all local variables be initialized before use rejecting incorrect programs issuing warnings Semantic analysis usually requires complete parse tree meaning that this phase logically follows parsing phase logically precedes code generation phase though it often possible fold multiple phases into one pass over code in compiler implementation Middle end edit middle end also known as optimizer performs optimizations on intermediate representation in order improve performance quality produced machine code middle end contains those optimizations that are independent CPU architecture being targeted main phases middle end include following Analysis This gathering program information from intermediate representation derived from input data flow analysis used build use define chains together with dependence analysis alias analysis pointer analysis escape analysis etc Accurate analysis basis any compiler optimization control flow graph every compiled function call graph program are usually also built during analysis phase Optimization intermediate language representation transformed into functionally equivalent but faster smaller forms Popular optimizations are inline expansion dead code elimination constant propagation loop transformation even automatic parallelization Compiler analysis prerequisite any compiler optimization they tightly work together example dependence analysis crucial loop transformation scope compiler analysis optimizations vary greatly scope may range from operating within basic block whole procedures even whole program trade off between granularity optimizations cost compilation example peephole optimizations are fast perform during compilation but only affect small local fragment code can be performed independently context in which code fragment appears In contrast interprocedural optimization requires more compilation time memory space but enable optimizations which are only possible by considering behavior multiple functions simultaneously Interprocedural analysis optimizations are common in modern commercial compilers from HP IBM SGI Intel Microsoft Sun Microsystems free software GCC was criticized long time lacking powerful interprocedural optimizations but it changing in this respect Another open source compiler with full analysis optimization infrastructure Open which used by many organizations research commercial purposes Due extra time space needed compiler analysis optimizations some compilers skip them by default Users have use compilation options explicitly tell compiler which optimizations should be enabled Back end edit back end responsible CPU architecture specific optimizations code generation main phases back end include following Machine dependent optimizations optimizations that depend on details CPU architecture that compiler targets prominent example peephole optimizations which rewrites short sequences assembler instructions into more efficient instructions Code generation transformed intermediate language translated into output language usually native machine language system This involves resource storage decisions such as deciding which variables fit into registers memory selection scheduling appropriate machine instructions along with associated addressing modes see also Sethi Ullman algorithm Debug data may also need be generated facilitate debugging Compiler correctness edit Main article Compiler correctness Compiler correctness branch software engineering that deals with trying show that compiler behaves according its language specification self published source non primary source needed Techniques include developing compiler using formal methods using rigorous testing often called compiler validation on an existing compiler Compiled versus interpreted languages edit This section does not cite any sources Please help improve this section by adding citations reliable sources Unsourced material may be challenged removed Find sources Compiler news newspapers books scholar JSTOR October Learn remove this template message Higher level programming languages usually appear with type translation in mind either designed as compiled language interpreted language However in practice rarely anything about language that requires it be exclusively compiled exclusively interpreted although it possible design languages that rely on re interpretation at run time categorization usually reflects most popular widespread implementations language instance BASIC sometimes called an interpreted language C compiled one despite existence BASIC compilers C interpreters Interpretation does not replace compilation completely It only hides it from user makes it gradual Even though an interpreter can itself be interpreted directly executed program needed somewhere at bottom stack see machine language Further compilers can contain interpreters optimization reasons example an expression can be executed during compilation results inserted into output program then it prevents it having be recalculated each time program runs which can greatly speed up final program Modern trends toward just in time compilation bytecode interpretation at times blur traditional categorizations compilers interpreters even further Some language specifications spell out that implementations must include compilation facility example Common Lisp However nothing inherent in definition Common Lisp that stops it from being interpreted Other languages have features that are very easy implement in an interpreter but make writing compiler much harder example APL SNOBOL many scripting languages allow programs construct arbitrary source code at runtime with regular string operations then execute that code by passing it special evaluation function implement these features in compiled language programs must usually be shipped with runtime library that includes version compiler itself Types edit One classification compilers by platform on which generated code executes This known as target platform native hosted compiler one whose output intended directly run on same type computer operating system that compiler itself runs on output cross compiler designed run on different platform Cross compilers are often used developing software embedded systems that are not intended support software development environment output compiler that produces code virtual machine VM may may not be executed on same platform as compiler that produced it this reason such compilers are not usually classified as native cross compilers lower level language that target compiler may itself be high level programming language C viewed by some as sort portable assembly language frequently target language such compilers example Cfront original compiler C used C as its target language C code generated by such compiler usually not intended be readable maintained by humans so indent style creating pretty C intermediate code are ignored Some features C that make it good target language include line directive which can be generated by compiler support debugging original source wide platform support available with C compilers While common compiler type outputs machine code are many other types Source source compilers are type compiler that takes high level language as its input outputs high level language example an automatic parallelizing compiler will frequently take in high level language program as an input then transform code annotate it with parallel code annotations e g OpenMP language constructs e g Fortran s DOALL statements Bytecode compilers that compile assembly language theoretical machine like some Prolog implementations This Prolog machine also known as Warren Abstract Machine WAM Bytecode compilers Java Python are also examples this category Just in time compilers JIT compiler defer compilation until runtime JIT compilers exist many modern languages including Python JavaScript Smalltalk Java Microsoft NET s Common Intermediate Language CIL others JIT compiler generally runs inside an interpreter interpreter detects that code path hot meaning it executed frequently JIT compiler will be invoked compile hot code increased performance some languages such as Java applications are first compiled using bytecode compiler delivered in machine independent intermediate representation bytecode interpreter executes bytecode but JIT compiler will translate bytecode machine code increased performance necessary non primary source needed Hardware compilers also known as syntheses tools are compilers whose output description hardware configuration instead sequence instructions output these compilers target computer hardware at very low level example field programmable gate array FPGA structured application specific integrated circuit ASIC non primary source needed Such compilers are said be hardware compilers source code they compile effectively controls final configuration hardware it operates output compilation only an interconnection transistors lookup tables An example hardware compiler XST Xilinx Synthesis Tool used configuring FPGAs non primary source needed Similar tools are available from Altera non primary source needed Synplicity Synopsys other hardware vendors citation needed An assembler program that compiles human readable assembly language machine code actual instructions executed by hardware inverse program that translates machine code assembly language called disassembler program that translates from low level language higher level one decompiler citation needed program that translates between high level languages usually called language translator source source compiler language converter language rewriter citation needed last term usually applied translations that do not involve change language program that translates into an object code format that not supported on compilation machine called cross compiler commonly used prepare code embedded applications citation needed clarification needed program that rewrites object code back into same type object code while applying optimisations transformations binary recompiler See also edit Computer programming portal Book Compiler construction Abstract interpretation Bottom up parsing Compile go loader Compile farm List compilers List important publications in computer science Compilers Metacompilation Notes edit PC Mag Staff February Encyclopedia Definition Compiler PCMag com Retrieved February b Compilers Principles Techniques Tools by Alfred V Aho Ravi Sethi Jeffrey D Ullman Second Edition Sun Chengnian Le Vu Zhang Qirun Su Zhendong Toward Understanding Compiler Bugs in GCC LLVM ACM lecture notes Compilers Principles Techniques Tools Jing Shin Chang Department Computer Science Information Engineering National Chi Nan University Naur P et al Report on ALGOL Communications ACM May Chomsky Noam Lightfoot David W Syntactic Structures Walter de Gruyter ISBN Gries David Appendix Backus Naur Form Science Programming Springer Science Business Media p ISBN Iverson Kenneth E Programming Language John Wiley Sons ISBN Backus John history FORTRAN II III PDF History Programming Languages Softwarepreservation org Porter Adams Vicki October Captain Grace M Hopper Mother COBOL InfoWorld ISSN McCarthy J Brayton R Edwards D Fox P Hodes L Luckham D Maling K Park D Russell S March LISP Programmers Manual PDF Boston Massachusetts Artificial Intelligence Group M T Computation Center Research Laboratory Compilers Principles Techniques Tools nd edition by Aho Lam Sethi Ullman ISBN Hopper Grace Murray Education Computer Proceedings ACM National Meeting Pittsburgh doi Ridgway Richard K Compiling routines Proceedings ACM National Meeting Toronto doi Recursive Functions Symbolic Expressions Computation by Machine Communications ACM April McCarthy John Abrahams Paul W Edwards Daniel J Hart Timothy P Levin Michael Lisp Programmers Manual MIT Press ISBN BCPL tool compiler writing system programming M Richards University Mathematical Laboratory Cambridge England BCPL Language Its Compiler M Richards Cambridge University Press first published December BCPL Cintsys Cintpos User Guide M Richards Corbat F J Vyssotsky V Introduction Overview MULTICS System Fall Joint Computer Conference Multicians org Report II SHARE Advanced Language Development Committee June Multicians org Choice PL article Editor tom Van Vleck PL As Tool System Programming F J Corbato Datamation May issue Multics PL Compiler R Freiburghouse GE Fall Joint Computer Conference Datamation column Dennis M Ritchie Development C Language ACM Second History Programming Languages Conference April S C Johnson Portable C Compiler Theory Practice th ACM POPL Symposium January Snyder Portable Compiler Language C MIT K Nygarard University Oslo Norway Basic Concepts in Object Oriented Programming SIGPLAN Notices V B Stroustrup Object Oriented Programming Proceedings th ASU Conference Bjarne Stroustrup An Overview C Programming Language Handbook Object Technology Editor Saba Zamir ISBN Leverett Cattell Hobbs Newcomer Reiner Schatz Wulf An Overview Production Quality Compiler Compiler Project CMU CS W Wulf K Nori Delayed binding in PQCC generated compilers CMU Research Showcase Report CMU CS Joseph M Newcomer David Alex Lamb Bruce W Leverett Michael Tighe William Wulf Carnegie Mellon University David Levine Andrew H Reinerit Intermetrics TCOL Ada Revised Report on An Intermediate Representation DOD Standard Programming Language William Whitaker Ada project DoD High Order Working Group ACM SIGPLAN Notices Volume No March CECOM Center Software Engineering Advanced Software Technology Final Report Evaluation ACEC Benchmark Suite Real Time Applications AD P Biggar E de Vries D Gregg Practical Solution Scripting Language Compilers submission Science Computer Programming M Hall D Padua K Pingali Compiler Research Next Years ACM Communications Vol Cooper Torczon p Lattner Chris LLVM In Brown Amy Wilson Greg eds Architecture Open Source Applications Archived from original on December Retrieved February Aho Lam Sethi Ullman p Aho Lam Sethi Ullman p Aho Lam Sethi Ullman p b Blindell Gabriel Hjort June Instruction selection principles methods applications Switzerland ISBN OCLC Cooper Toczon p Chlipala Adam Syntactic Proofs Compositional Compiler Correctness manuscript draft publication date unknown Archived PDF from original on August Retrieved February via Adam Chlipala net self published source non primary source needed Aycock John Brief History Just in Time ACM Comput Surv June doi non primary source needed Swartz Jordan S Betz Vaugh Rose Jonathan February Fast Routability Driven Router FPGAs PDF FPGA Proceedings ACM SIGDA Sixth International Symposium on Field Programmable Gate Arrays Monterey CA ACM doi ISBN Archived PDF from original on August Xilinx Staff XST Synthesis Overview Xilinx Inc Archived from original on November Retrieved February non primary source needed Altera Staff Spectra Q Engine Altera com Archived from original on October Retrieved February non primary source needed Language Translator Tutorial PDF Washington University References edit LLVM community LLVM Target Independent Code Generator LLVM Documentation Retrieved June Compiler textbook references collection references mainstream Compiler Construction Textbooks Aho Alfred V Sethi Ravi Ullman Jeffrey D Compilers Principles Techniques Tools st ed Addison Wesley ISBN Allen Frances E September History Language Processor Technology in IBM IBM Journal Research Development IBM doi rd Allen Randy Kennedy Ken Optimizing Compilers Modern Architectures Morgan Kaufmann Publishers ISBN Appel Andrew Wilson Modern Compiler Implementation in Java nd ed Cambridge University Press ISBN Appel Andrew Wilson Modern Compiler Implementation in ML Cambridge University Press ISBN Bornat Richard Understanding Writing Compilers Do It Yourself Guide PDF Macmillan Publishing ISBN Cooper Keith Daniel Torczon Linda Engineering compiler nd ed Amsterdam Elsevier Morgan Kaufmann p ISBN OCLC McKeeman William Marshall Horning James J Wortman David B Compiler Generator Englewood Cliffs NJ Prentice Hall ISBN Muchnick Steven Advanced Compiler Design Implementation Morgan Kaufmann Publishers ISBN Scott Michael Lee Programming Language Pragmatics nd ed Morgan Kaufmann ISBN Srikant Y N Shankar Priti Compiler Design Handbook Optimizations Machine Code Generation CRC Press ISBN Terry Patrick D Compilers Compiler Generators An Introduction with C International Thomson Computer Press ISBN Wirth Niklaus Compiler Construction PDF Addison Wesley ISBN External links edit Look up compiler in Wiktionary free dictionary Wikibooks has book on topic Compiler Construction Wikimedia Commons has media related Compilers Compilers at Curlie Incremental Approach Compiler Construction PDF tutorial Compile Howto Basics Compiler Design at Wayback Machine archived Short animation on YouTube explaining key conceptual difference between compilers interpreters Syntax Analysis LL Parsing on YouTube Let s Build Compiler by Jack Crenshaw Forum about compiler development at Wayback Machine archived Difference Between Compiler Interpreter Authority control BNE XX BNF cb data GND LCCN sh NDL Retrieved from https en wikipedia org w index php title Compiler oldid Categories American inventions Compilers Compiler construction Computer libraries Programming language implementation Utility software types Hidden categories All articles with self published sources Articles with self published sources from March All pages needing factual verification Wikipedia articles needing factual verification from March Use dmy dates from July Articles needing additional references from September All articles needing additional references Articles needing additional references from October All articles with unsourced statements Articles with unsourced statements from March Wikipedia articles needing clarification from February Commons category link on Wikidata Articles with Curlie links Webarchive template wayback links Wikipedia articles with BNE identifiers Wikipedia articles with BNF identifiers Wikipedia articles with GND identifiers Wikipedia articles with LCCN identifiers Wikipedia articles with NDL identifiers Navigation menu Personal tools Not logged in Talk Contributions Create account Log in Namespaces Article Talk Variants Views Read Edit View history More Search Navigation Main page Contents Featured content Current events Random article Donate Wikipedia Wikipedia store Interaction Help About Wikipedia Community portal Recent changes Contact page Tools links here Related changes Upload file Special pages Permanent link Page information Wikidata item Cite this page In other projects Wikimedia Commons Print export Create book Download as PDF Printable version Languages Afrikaans Aragon s Asturianu Az rbaycanca B n l m g Bosanski Catal e tina Dansk Deutsch Eesti Espa ol Esperanto Euskara Fran ais Gaeilge Galego Hornjoserbsce Hrvatski Ilokano Bahasa Indonesia Interlingua slenska Italiano Latina Latvie u L tzebuergesch Lietuvi Lingua Franca Nova Magyar Bahasa Melayu Mirand s Nederlands Norsk Polski Portugu s Rom n Scots Simple English Sloven ina Sloven ina srpski Srpskohrvatski Suomi Svenska Tagalog T rk e Ti ng Vi t Winaray Zazaki Edit links This page was last edited on November at UTC Text available under Creative Commons Attribution ShareAlike License additional terms may apply By using this site agree Terms Use Privacy Policy Wikipedia registered trademark Wikimedia Foundation Inc non profit organization Privacy policy About Wikipedia Disclaimers Contact Wikipedia Developers Statistics Cookie statement Mobile view